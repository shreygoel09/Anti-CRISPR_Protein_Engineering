{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","mount_file_id":"1A35mIVAT9SK08cmxp_eouVLU8C6LlonX","authorship_tag":"ABX9TyMQcX0fG8BfPr3ArFNRb4rR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### imports"],"metadata":{"id":"ISqX09sjq4xn"}},{"cell_type":"code","source":["import os"],"metadata":{"id":"U_Ai7jMWPOMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers[torch]\n","!pip install datasets\n","!pip install evaluate"],"metadata":{"id":"YPC2SzpvPToz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers"],"metadata":{"id":"tf-jMXD7E01h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwnrETGBNu-5"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"nferruz/ProtGPT2\")\n","model = AutoModelForCausalLM.from_pretrained(\"nferruz/ProtGPT2\")"]},{"cell_type":"markdown","source":["### fine-tune ProtGPT"],"metadata":{"id":"jVahwxY3q6PW"}},{"cell_type":"code","source":["\"\"\"\n","Here, we fine-tune ProtGPT2 on anti-crispr sequences. We train the model over 100 epochs with a learning rate of 0.0003.\n","A small batch size of 2 is used due to the limited GPU memory available. We log the training and evaluation results every epoch to assess the model's performance.\n","\"\"\""],"metadata":{"id":"-siMI0tMtWZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Use run_clm.py to fine-tune ProtGPT2 on sequences\n","!python run_clm.py \\\n","  --model_name_or_path nferruz/ProtGPT2 \\\n","  --train_file train.txt \\\n","  --validation_file test.txt \\\n","  --tokenizer_name nferruz/ProtGPT2 \\\n","  --num_train_epochs 100 \\\n","  --logging_steps 1 \\\n","  --logging_dir 'test' \\\n","  --do_train \\\n","  --do_eval \\\n","  --output_dir \"/content/drive/MyDrive/Duke/Freshman Year/Sem 2/BME 590/Shrey Goel/Individual Project 2A/finetuned_protgpt2_model\" \\\n","  --overwrite_output_dir \\\n","  --learning_rate 3e-04 \\\n","  --per_device_train_batch_size 2 \\\n","  --evaluation_strategy epoch"],"metadata":{"id":"xyO2CezebxnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize training/evaluation results with tensorboard\n","%reload_ext tensorboard\n","%tensorboard --logdir 'test'"],"metadata":{"id":"J_4zh4rtM7dK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zilGrwbybygl"},"execution_count":null,"outputs":[]}]}